# ğŸ§  LLM Code Style Reviewer

An AI-powered GitHub Action that performs static and LLM-based code
review for Pull Requests.

This action:

-   Detects changed files in a PR\
-   Runs configurable static checks\
-   Sends code to an LLM provider (currently OpenAI) for deeper
    analysis\
-   Outputs structured review feedback in GitHub Actions logs

------------------------------------------------------------------------

## ğŸš€ Features

-   ğŸ” Automatic PR diff detection\
-   ğŸ“ Rule-based static checks (configurable via YAML)\
-   ğŸ¤– LLM-powered semantic code review\
-   ğŸ³ Docker-based isolated execution\
-   âš™ï¸ Modular architecture (static â†’ LLM â†’ pipeline)\
-   ğŸ”Œ Extendable provider system (supports multiple AI backends)

------------------------------------------------------------------------

## ğŸ“š Supported Language

-   Java (static + LLM review)

------------------------------------------------------------------------

## ğŸ”§ Installation

Create a workflow file:

`.github/workflows/llm-review.yml`

``` yaml
name: LLM Code Review

on:
  pull_request:

jobs:
  review:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run LLM Code Reviewer
        uses: varuuuun/llm-code-style-reviewer@v1
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
```

------------------------------------------------------------------------

## ğŸ” Required Secret

Add your OpenAI API key:

Settings â†’ Secrets and variables â†’ Actions â†’ Repository secrets

-   Name: `OPENAI_API_KEY`
-   Value: your-api-key

------------------------------------------------------------------------

## ğŸ§  How It Works

1.  Detects PR base branch automatically\

2.  Fetches base branch\

3.  Runs:

        git diff origin/<base>...HEAD

4.  Filters changed `.java` files\

5.  Runs static rule checks\

6.  Sends content to LLM provider for structured review\

7.  Prints warnings in workflow logs

------------------------------------------------------------------------

## âš™ï¸ Configuration

### Static Rules

Located at:

    data/coding_standard/rules.yaml

### LLM Rules

Located at:

    src/rules/llm_rules.yaml

### Local Config (For Local Testing)

    config.yaml

-   Used for local testing when GitHub Secrets are not available\
-   Stores API keys locally\
-   Committed version contains placeholder values only\
-   Not used inside GitHub Actions (Actions use repository secrets)

------------------------------------------------------------------------

## ğŸ”Œ Provider Architecture

`providers.py` makes the project extendable to additional AI providers.

-   Currently supported: **OpenAI**
-   To support another provider (e.g., Anthropic, Azure OpenAI),
    implement a new provider class inside `providers.py`
-   The architecture allows extension without modifying core pipeline
    logic

------------------------------------------------------------------------

## ğŸ— Architecture

    Docker Action
    â”œâ”€â”€ action.yaml
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ run_action.py
    â”‚   â””â”€â”€ run.py
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ analysis/
    â”‚   â”œâ”€â”€ reviewer/
    â”‚   â”œâ”€â”€ llm/
    â”‚   â””â”€â”€ rules/
    â”œâ”€â”€ data/
    â”œâ”€â”€ config.yaml
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ README.md

Pipeline Flow:

Static Checks â†’ LLM Review â†’ Aggregated Output

------------------------------------------------------------------------

## â— Failure Behavior

-   Static and LLM warnings are printed\
-   Workflow exits with non-zero only if script errors occur\
-   Future versions may support strict mode

------------------------------------------------------------------------

## ğŸ” Privacy & Cost Notice

This action sends changed Java files to an external LLM provider.

Ensure:

-   You are comfortable sending code externally\
-   You understand API usage may incur cost

------------------------------------------------------------------------

## ğŸ§ª Local Testing

1. Add your OpenAI API key to `config.yaml`:

``` yaml
provider: openai
openai:
  model: gpt-4
  api_key: your-api-key-here
```

2. Run the reviewer on a file:

``` bash
python scripts.run /path/to/your/file.java
```

------------------------------------------------------------------------

## ğŸ“ˆ Roadmap

-   [ ] Strict mode (fail on violations)\
-   [ ] Inline PR comments via GitHub API\
-   [ ] Multi-language support\
-   [ ] Configurable severity levels\
-   [ ] Additional LLM providers

------------------------------------------------------------------------

## ğŸ“œ License

MIT License

------------------------------------------------------------------------

Built by Varun
