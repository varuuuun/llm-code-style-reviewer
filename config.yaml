# LLM Configuration
# Specify which LLM provider to use and its credentials

# Provider can be: openai, gemini, claude, or local
provider: openai

# OpenAI Configuration
openai:
  api_key: "sk-placeholder-your-openai-key-here"
  model: "gpt-4o-mini"
  base_url: null  # Leave null for default, or specify custom endpoint
  temperature: 0.7
  max_tokens: 1000
  